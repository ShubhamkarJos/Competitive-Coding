{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sales.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlLeKWOtGyMr"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qzkTivxSiYM"
      },
      "source": [
        "dataset = pd.read_csv('Sheet2.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMm7YR4SocY",
        "outputId": "42e08b4a-b2a0-4023-b8c4-b2628788d8d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unit price</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Tax 5%</th>\n",
              "      <th>Total</th>\n",
              "      <th>cogs</th>\n",
              "      <th>gross margin percentage</th>\n",
              "      <th>gross income</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1.000000e+03</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>55.672130</td>\n",
              "      <td>5.510000</td>\n",
              "      <td>15.379369</td>\n",
              "      <td>322.966749</td>\n",
              "      <td>307.58738</td>\n",
              "      <td>4.761905e+00</td>\n",
              "      <td>15.379369</td>\n",
              "      <td>6.97270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>26.494628</td>\n",
              "      <td>2.923431</td>\n",
              "      <td>11.708825</td>\n",
              "      <td>245.885335</td>\n",
              "      <td>234.17651</td>\n",
              "      <td>6.220360e-14</td>\n",
              "      <td>11.708825</td>\n",
              "      <td>1.71858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10.080000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.508500</td>\n",
              "      <td>10.678500</td>\n",
              "      <td>10.17000</td>\n",
              "      <td>4.761905e+00</td>\n",
              "      <td>0.508500</td>\n",
              "      <td>4.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>32.875000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.924875</td>\n",
              "      <td>124.422375</td>\n",
              "      <td>118.49750</td>\n",
              "      <td>4.761905e+00</td>\n",
              "      <td>5.924875</td>\n",
              "      <td>5.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.230000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>12.088000</td>\n",
              "      <td>253.848000</td>\n",
              "      <td>241.76000</td>\n",
              "      <td>4.761905e+00</td>\n",
              "      <td>12.088000</td>\n",
              "      <td>7.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>77.935000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>22.445250</td>\n",
              "      <td>471.350250</td>\n",
              "      <td>448.90500</td>\n",
              "      <td>4.761905e+00</td>\n",
              "      <td>22.445250</td>\n",
              "      <td>8.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>99.960000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>49.650000</td>\n",
              "      <td>1042.650000</td>\n",
              "      <td>993.00000</td>\n",
              "      <td>4.761905e+00</td>\n",
              "      <td>49.650000</td>\n",
              "      <td>10.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unit price     Quantity  ...  gross income      Rating\n",
              "count  1000.000000  1000.000000  ...   1000.000000  1000.00000\n",
              "mean     55.672130     5.510000  ...     15.379369     6.97270\n",
              "std      26.494628     2.923431  ...     11.708825     1.71858\n",
              "min      10.080000     1.000000  ...      0.508500     4.00000\n",
              "25%      32.875000     3.000000  ...      5.924875     5.50000\n",
              "50%      55.230000     5.000000  ...     12.088000     7.00000\n",
              "75%      77.935000     8.000000  ...     22.445250     8.50000\n",
              "max      99.960000    10.000000  ...     49.650000    10.00000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtoLsDt3TCja",
        "outputId": "5612a014-c6b1-400a-f0b4-0cdbd527f578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 17 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Time                     1000 non-null   object \n",
            " 1   Date                     1000 non-null   object \n",
            " 2   Invoice ID               1000 non-null   object \n",
            " 3   Branch                   1000 non-null   object \n",
            " 4   City                     1000 non-null   object \n",
            " 5   Customer type            1000 non-null   object \n",
            " 6   Gender                   1000 non-null   object \n",
            " 7   Payment                  1000 non-null   object \n",
            " 8   Product line             1000 non-null   object \n",
            " 9   Unit price               1000 non-null   float64\n",
            " 10  Quantity                 1000 non-null   int64  \n",
            " 11  Tax 5%                   1000 non-null   float64\n",
            " 12  Total                    1000 non-null   float64\n",
            " 13  cogs                     1000 non-null   float64\n",
            " 14  gross margin percentage  1000 non-null   float64\n",
            " 15  gross income             1000 non-null   float64\n",
            " 16  Rating                   1000 non-null   float64\n",
            "dtypes: float64(7), int64(1), object(9)\n",
            "memory usage: 132.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo7rPDh2T6W4"
      },
      "source": [
        "X = dataset.iloc[:,3:15].values\n",
        "y = dataset.iloc[:,-2].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSobqE7eTtoy"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckdM2AhxUI_H",
        "outputId": "e8ef2085-16ae-4d36-89ab-2eec15581e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 'A' ... 457.44300000000004 435.66 4.7619047619999995]\n",
            " [0.0 1.0 'A' ... 399.756 380.72 4.7619047619999995]\n",
            " [1.0 0.0 'B' ... 470.673 448.26 4.7619047619999995]\n",
            " ...\n",
            " [1.0 0.0 'A' ... 216.84599999999998 206.52 4.7619047619999995]\n",
            " [1.0 0.0 'A' ... 469.77 447.4 4.7619047619999995]\n",
            " [0.0 1.0 'C' ... 304.983 290.46 4.7619047619999995]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-il5XlIbUPHk"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9HP9WdeUTNz",
        "outputId": "b60c3b8f-b9eb-43fd-ef99-bc7d2c2fe367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 ... 457.44300000000004 435.66 4.7619047619999995]\n",
            " [1.0 0.0 0.0 ... 399.756 380.72 4.7619047619999995]\n",
            " [0.0 1.0 0.0 ... 470.673 448.26 4.7619047619999995]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 216.84599999999998 206.52 4.7619047619999995]\n",
            " [1.0 0.0 0.0 ... 469.77 447.4 4.7619047619999995]\n",
            " [0.0 0.0 1.0 ... 304.983 290.46 4.7619047619999995]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gna7qZgZUbk-"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [5])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkvpoUaVUf-l"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [8])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTYA4WkFUlI6"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [10])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZQBWmjCUm-g"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [13])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EyU9SCNUqQs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OGKzogFUvAC",
        "outputId": "edc275e7-16c2-4f82-d5a9-0021d622b53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h26pEaRyUyzh",
        "outputId": "394e3d8b-8d75-42a9-b525-393ccf42b122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=1)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[29.  29. ]\n",
            " [16.4 16.4]\n",
            " [ 3.2  3.2]\n",
            " [45.3 45.2]\n",
            " [ 4.9  4.9]\n",
            " [17.5 17.5]\n",
            " [ 2.7  2.7]\n",
            " [23.2 23.2]\n",
            " [ 1.6  1.6]\n",
            " [ 8.8  8.8]\n",
            " [ 5.3  5.3]\n",
            " [10.2 10.2]\n",
            " [ 2.8  2.8]\n",
            " [ 7.   7. ]\n",
            " [ 7.9  7.9]\n",
            " [12.2 12.2]\n",
            " [17.2 17.2]\n",
            " [23.6 23.6]\n",
            " [24.3 24.3]\n",
            " [24.8 24.8]\n",
            " [18.3 18.3]\n",
            " [15.4 15.4]\n",
            " [12.2 12.2]\n",
            " [45.  45. ]\n",
            " [ 4.7  4.7]\n",
            " [25.5 25.5]\n",
            " [20.6 20.6]\n",
            " [12.1 12.1]\n",
            " [20.1 20.1]\n",
            " [19.  19. ]\n",
            " [21.  21. ]\n",
            " [ 8.2  8.2]\n",
            " [ 6.5  6.5]\n",
            " [35.1 35.1]\n",
            " [19.5 19.5]\n",
            " [33.4 33.4]\n",
            " [ 6.2  6.2]\n",
            " [44.6 44.6]\n",
            " [ 7.9  7.9]\n",
            " [49.5 49.5]\n",
            " [ 0.5  0.5]\n",
            " [ 4.1  4.1]\n",
            " [ 3.3  3.3]\n",
            " [21.  21. ]\n",
            " [ 7.3  7.3]\n",
            " [10.  10. ]\n",
            " [ 9.7  9.7]\n",
            " [ 3.6  3.6]\n",
            " [ 0.8  0.8]\n",
            " [ 7.2  7.2]\n",
            " [22.7 22.7]\n",
            " [22.5 22.5]\n",
            " [16.6 16.6]\n",
            " [ 9.1  9.1]\n",
            " [38.5 38.5]\n",
            " [ 3.3  3.3]\n",
            " [ 1.   1. ]\n",
            " [13.  13. ]\n",
            " [25.1 25.1]\n",
            " [44.5 44.5]\n",
            " [20.  20. ]\n",
            " [36.1 36.1]\n",
            " [11.4 11.4]\n",
            " [ 9.7  9.7]\n",
            " [20.8 20.8]\n",
            " [ 7.9  7.9]\n",
            " [ 1.7  1.7]\n",
            " [ 2.7  2.7]\n",
            " [18.2 18.2]\n",
            " [ 9.2  9.2]\n",
            " [ 2.4  2.4]\n",
            " [ 1.1  1.1]\n",
            " [ 8.7  8.7]\n",
            " [37.3 37.3]\n",
            " [23.6 23.6]\n",
            " [14.3 14.3]\n",
            " [48.8 48.8]\n",
            " [ 2.1  2.1]\n",
            " [14.  14. ]\n",
            " [ 1.5  1.5]\n",
            " [ 3.6  3.6]\n",
            " [31.8 31.8]\n",
            " [ 1.4  1.4]\n",
            " [43.9 43.9]\n",
            " [18.6 18.6]\n",
            " [ 3.   3. ]\n",
            " [ 1.6  1.6]\n",
            " [ 6.2  6.2]\n",
            " [ 9.3  9.3]\n",
            " [33.8 33.8]\n",
            " [31.8 31.8]\n",
            " [11.9 11.9]\n",
            " [ 7.4  7.4]\n",
            " [15.4 15.4]\n",
            " [ 3.8  3.8]\n",
            " [ 9.5  9.5]\n",
            " [22.4 22.4]\n",
            " [13.7 13.7]\n",
            " [38.6 38.6]\n",
            " [39.5 39.5]\n",
            " [19.1 19.1]\n",
            " [ 8.2  8.2]\n",
            " [13.3 13.3]\n",
            " [ 4.   4. ]\n",
            " [33.4 33.4]\n",
            " [10.7 10.7]\n",
            " [28.  28. ]\n",
            " [23.1 23.1]\n",
            " [ 2.6  2.6]\n",
            " [27.4 27.4]\n",
            " [ 1.2  1.2]\n",
            " [30.5 30.5]\n",
            " [ 3.9  3.9]\n",
            " [15.4 15.4]\n",
            " [ 8.3  8.3]\n",
            " [ 5.7  5.7]\n",
            " [ 3.   3. ]\n",
            " [ 9.   9. ]\n",
            " [13.6 13.6]\n",
            " [33.6 33.6]\n",
            " [ 2.7  2.7]\n",
            " [ 9.9  9.9]\n",
            " [ 4.3  4.3]\n",
            " [10.6 10.6]\n",
            " [ 3.9  3.9]\n",
            " [ 4.6  4.6]\n",
            " [ 4.   4. ]\n",
            " [10.2 10.2]\n",
            " [29.9 29.9]\n",
            " [10.7 10.7]\n",
            " [36.2 36.2]\n",
            " [ 2.6  2.6]\n",
            " [ 3.7  3.7]\n",
            " [34.9 34.9]\n",
            " [34.  34. ]\n",
            " [ 7.6  7.6]\n",
            " [22.6 22.6]\n",
            " [37.1 37.1]\n",
            " [ 1.5  1.5]\n",
            " [ 2.7  2.7]\n",
            " [17.6 17.6]\n",
            " [12.6 12.6]\n",
            " [ 7.7  7.7]\n",
            " [ 0.6  0.6]\n",
            " [13.9 13.9]\n",
            " [25.6 25.6]\n",
            " [20.  20. ]\n",
            " [30.2 30.2]\n",
            " [ 1.4  1.4]\n",
            " [12.7 12.7]\n",
            " [ 6.3  6.3]\n",
            " [17.1 17.1]\n",
            " [ 8.3  8.3]\n",
            " [12.4 12.4]\n",
            " [ 5.8  5.8]\n",
            " [14.1 14.1]\n",
            " [23.7 23.7]\n",
            " [29.  29. ]\n",
            " [15.5 15.5]\n",
            " [ 4.4  4.4]\n",
            " [ 1.1  1.1]\n",
            " [10.9 10.9]\n",
            " [16.4 16.4]\n",
            " [10.2 10.2]\n",
            " [36.7 36.7]\n",
            " [14.  14. ]\n",
            " [ 6.1  6.1]\n",
            " [11.8 11.8]\n",
            " [41.  41. ]\n",
            " [21.8 21.8]\n",
            " [11.1 11.1]\n",
            " [ 5.   5. ]\n",
            " [ 1.6  1.6]\n",
            " [29.8 29.8]\n",
            " [11.2 11.2]\n",
            " [ 3.6  3.6]\n",
            " [10.  10. ]\n",
            " [ 6.5  6.5]\n",
            " [23.1 23.1]\n",
            " [32.9 32.9]\n",
            " [17.  17. ]\n",
            " [14.5 14.5]\n",
            " [ 6.6  6.6]\n",
            " [26.1 26.1]\n",
            " [43.7 43.7]\n",
            " [ 1.3  1.3]\n",
            " [12.7 12.7]\n",
            " [ 9.3  9.3]\n",
            " [20.5 20.5]\n",
            " [16.8 16.8]\n",
            " [10.6 10.6]\n",
            " [21.3 21.3]\n",
            " [20.2 20.2]\n",
            " [ 6.3  6.3]\n",
            " [ 9.8  9.8]\n",
            " [17.3 17.3]\n",
            " [16.7 16.7]\n",
            " [ 4.1  4.1]\n",
            " [ 4.1  4.1]\n",
            " [19.3 19.3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vdezx2pKCLQ"
      },
      "source": [
        "x_plot = dataset.iloc[:, [8,10]]  "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkBsnptAKhyV",
        "outputId": "20dac6d6-13a9-4e64-ba45-f57661ad2f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "print(x_plot)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               Product line  Quantity\n",
            "0         Sports and travel         6\n",
            "1        Home and lifestyle         8\n",
            "2    Electronic accessories         6\n",
            "3         Sports and travel        10\n",
            "4    Electronic accessories         2\n",
            "..                      ...       ...\n",
            "995      Food and beverages         2\n",
            "996     Fashion accessories         8\n",
            "997      Home and lifestyle         6\n",
            "998       Sports and travel         5\n",
            "999  Electronic accessories         3\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seMLWc-iNTxA"
      },
      "source": [
        "a = dataset.iloc[:,8].values"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui2FxlF2OrNi"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpbuI9fbOzJ1"
      },
      "source": [
        "for i in range(len(a)):\n",
        "  if a[i] == \"Sports and travel\":\n",
        "    a[i] = 0\n",
        "  elif a[i] == \"Home and lifestyle\":\n",
        "    a[i] = 1\n",
        "  elif a[i] == \"Electronic accessories\":\n",
        "    a[i] = 2\n",
        "  elif a[i] == \"Fashion accessories\":\n",
        "    a[i] = 3\n",
        "  elif a[i] == \"Health and beauty\":\n",
        "    a[i] = 4\n",
        "  elif a[i] == \"Food and beverages\":\n",
        "    a[i] = 5"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M5I2trXQO4M",
        "outputId": "9e427227-6fb0-4f7f-c82c-90f2f09d1e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "print(a)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 0 2 4 3 0 2 0 5 5 2 1 0 5 5 4 3 2 5 1 3 4 4 2 3 5 0 3 4 3 2 5 0 0 1\n",
            " 4 5 1 5 3 2 3 5 0 3 5 2 3 0 3 2 2 0 1 0 0 4 1 0 3 4 2 0 5 2 1 4 4 4 1 4 0\n",
            " 1 4 5 0 1 3 5 0 0 0 5 1 0 5 5 3 1 1 2 2 5 1 2 4 5 4 4 1 3 2 2 2 0 1 3 4 2\n",
            " 1 2 1 3 0 3 4 5 2 5 5 0 4 2 2 1 4 4 3 4 1 5 4 3 1 1 1 3 1 3 5 3 4 2 0 4 4\n",
            " 1 3 5 4 0 3 5 5 2 4 5 5 0 1 3 5 3 3 4 4 4 1 2 0 1 4 5 1 0 3 5 1 4 0 3 3 5\n",
            " 5 4 4 3 1 2 4 4 5 2 1 0 0 1 5 0 1 2 4 0 2 3 0 3 2 1 3 1 5 0 5 5 4 5 2 1 2\n",
            " 2 5 1 0 2 3 4 3 0 2 1 2 3 3 1 1 3 4 5 2 1 2 1 3 5 5 1 3 0 0 3 1 0 1 3 2 5\n",
            " 0 2 5 5 0 3 0 0 3 1 3 4 1 3 0 1 2 2 4 4 3 3 1 5 1 5 5 3 0 3 0 3 1 1 2 2 3\n",
            " 2 0 5 5 1 3 5 1 4 1 5 2 2 2 0 0 3 4 5 0 3 3 4 5 0 1 3 4 0 0 1 2 3 0 2 5 2\n",
            " 5 4 0 3 1 2 2 3 3 1 3 0 1 5 5 0 3 5 4 1 2 2 0 3 5 0 5 5 5 1 3 1 4 5 5 0 1\n",
            " 1 4 1 0 0 1 4 4 5 1 3 2 3 2 0 4 4 3 3 1 2 0 1 2 3 1 4 5 2 0 3 2 4 4 2 0 4\n",
            " 4 0 5 1 5 1 2 3 2 3 5 0 0 4 5 1 2 5 3 5 5 3 3 0 5 4 4 4 2 0 2 3 5 1 0 5 4\n",
            " 2 4 1 1 2 3 1 5 0 3 0 0 1 5 0 1 1 0 5 5 1 0 0 5 0 4 2 5 4 1 3 3 0 0 3 1 5\n",
            " 5 2 1 0 0 0 0 2 5 3 2 2 1 5 1 1 0 1 0 1 3 3 4 4 5 4 1 5 1 4 0 5 1 4 4 1 1\n",
            " 4 5 5 1 0 5 3 2 1 2 2 3 5 4 3 4 5 4 4 0 2 4 3 3 0 2 1 1 2 2 1 0 5 3 3 4 4\n",
            " 2 5 1 4 3 0 4 0 1 0 3 3 5 0 5 1 4 3 2 3 0 3 3 5 3 3 4 5 2 4 0 1 0 3 2 5 1\n",
            " 3 5 1 4 2 1 0 0 4 1 4 3 4 2 2 4 2 4 5 4 3 0 3 3 2 5 0 0 1 2 0 4 0 5 2 1 5\n",
            " 2 1 2 0 2 2 2 0 0 0 3 2 2 3 2 2 3 3 3 2 2 3 0 3 0 5 4 2 5 0 5 0 4 4 0 3 1\n",
            " 1 4 4 3 3 5 2 2 5 4 5 4 3 4 0 2 0 3 3 2 3 4 3 5 2 2 5 2 1 5 5 0 0 3 2 0 4\n",
            " 3 1 2 4 4 2 3 5 0 2 2 4 2 3 4 5 5 5 5 4 4 5 5 1 1 0 2 3 3 0 4 4 5 0 3 3 3\n",
            " 2 0 1 1 3 1 5 2 5 0 5 4 5 2 1 1 0 2 3 4 2 1 5 2 2 3 0 4 5 4 0 0 3 1 4 2 2\n",
            " 5 5 2 0 4 5 3 3 0 2 5 4 4 3 4 5 0 3 2 3 3 5 4 2 5 2 3 3 5 4 2 4 1 5 3 4 5\n",
            " 3 0 3 3 1 2 5 3 2 1 2 2 3 5 2 4 2 3 5 0 0 0 1 4 4 2 1 3 0 3 4 4 0 1 4 0 5\n",
            " 1 0 5 0 3 2 3 5 0 1 1 0 1 2 0 3 1 1 3 3 4 4 2 2 3 2 3 0 1 2 2 1 1 5 3 1 5\n",
            " 3 0 5 0 1 2 3 0 5 5 3 1 0 1 2 2 0 2 5 1 3 0 1 1 0 0 0 2 5 4 5 3 5 0 1 3 1\n",
            " 1 3 2 5 0 1 0 1 1 3 2 1 4 1 2 3 2 5 0 2 5 2 4 3 4 2 0 2 5 4 1 4 3 3 4 2 1\n",
            " 5 4 0 5 2 5 5 5 3 5 3 2 2 5 5 5 5 3 4 4 4 2 4 4 1 4 2 4 0 4 2 5 4 5 3 1 0\n",
            " 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT5dzCGyIdzs",
        "outputId": "c8f3ca14-2074-4305-a5e2-bfd3c8e4f030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "plt.scatter(x_plot[a == 0, 0], x_plot[a == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\n",
        "plt.scatter(x_plot[a == 1, 0], x_plot[a == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\n",
        "plt.scatter(x_plot[a == 2, 0], x_plot[a == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\n",
        "plt.scatter(x_plot[a == 3, 0], x_plot[a == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\n",
        "plt.scatter(x_plot[a == 4, 0], x_plot[a == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\n",
        "plt.scatter(x_plot[a == 5, 0], x_plot[a == 5, 1], s = 100, c = 'orange', label = 'Cluster 6')\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\n",
        "plt.title('Clusters of customers')\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-da2624d7ef55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cluster 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cluster 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cluster 3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cyan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cluster 4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'magenta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cluster 5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(array([ True, False, False,  True, False, False, False,  True, False,\n        True, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False,  True,  True,\n       False, False, False, False, False, False, False, False, False,\n        True, False, False, False, False,  True, False, False, False,\n        True, False,  True,  True, False, False,  True, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False,  True, False, False, False,  True, False, False, False,\n        True,  True,  True, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False,  True,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n        True, False, False, False, False,  True, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True,  True,\n       False, False,  True, False, False, False,  True, False, False,\n        True, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n        True, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False,  True,  True,\n       False, False,  True, False, False, False, False,  True, False,\n       False, False,  True, False,  True,  True, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False, False, False,  True,\n       False,  True, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True,  True, False, False, False,\n        True, False, False, False, False,  True, False, False, False,\n        True,  True, False, False, False,  True, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False, False,  True, False, False, False,  True, False, False,\n       False, False, False, False,  True, False, False,  True, False,\n       False, False, False, False, False, False, False, False,  True,\n       False, False, False, False,  True,  True, False, False, False,\n       False, False, False, False, False, False,  True, False, False,\n       False, False, False, False,  True, False, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n        True, False, False,  True, False, False, False, False, False,\n       False, False, False, False,  True,  True, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False,  True, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False,  True, False,  True,  True, False, False,  True,\n       False, False,  True, False, False, False,  True,  True, False,\n        True, False, False, False, False, False, False, False,  True,\n        True, False, False, False, False, False, False,  True,  True,\n        True,  True, False, False, False, False, False, False, False,\n       False, False,  True, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False,  True, False, False,\n       False, False,  True, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False,  True, False,  True, False,  True, False, False,\n       False,  True, False, False, False, False, False, False,  True,\n       False, False, False, False, False, False, False, False, False,\n        True, False,  True, False, False, False, False, False, False,\n       False, False, False, False,  True,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False,  True,  True, False,\n       False,  True, False,  True, False, False, False, False, False,\n       False, False,  True, False, False, False,  True,  True,  True,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False,  True, False,  True, False, False, False,\n       False,  True, False,  True, False, False,  True, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False,  True, False,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False,  True,  True, False, False,  True,\n       False, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False,  True,\n       False, False, False,  True, False, False, False,  True, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False,  True, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False,  True,  True, False, False,\n       False, False, False, False, False, False,  True, False, False,\n       False, False,  True, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False,  True,  True,  True, False,\n       False, False, False, False, False,  True, False, False, False,\n        True, False, False,  True, False, False,  True, False,  True,\n       False, False, False, False,  True, False, False,  True, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False,  True, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n        True, False, False, False,  True, False, False, False, False,\n        True, False, False, False,  True, False, False, False, False,\n        True, False, False,  True,  True,  True, False, False, False,\n       False, False, False,  True, False, False, False, False, False,\n       False, False,  True, False,  True, False, False, False, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False, False, False, False,  True, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n        True, False, False, False, False, False, False, False,  True,\n       False]), 0)' is an invalid key"
          ]
        }
      ]
    }
  ]
}